<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title><b>Ming-Yu Liu 劉洺堉</b></title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>
<body>
<div id="header">
	<h1><a href="#"><b>Ming-Yu Liu 劉洺堉</b></a></h1>
</div>
</br>
<div id="menu">
	<ul>
        <li class=""><a href="index.html" accesskey="1" title="">Home</a></li>
        <li><a href="publication.html" accesskey="2" title="">Publication</a></li>        
        <li><a href="https://mingyuliu.blog" accesskey="6" title="">Blog</a></li>
	</ul>
</div>
<hr />
<div id="latest-post" class="post">
	<div class="entry"><img src="images/mingyu_2018.jpg" alt="" width="200" class="left" />		
		<p><h2>Ming-Yu Liu is a principal research scientist at NVIDIA Research. Before joining NVIDIA in 2016, he was a principal research scientist at Mitsubishi Electric Research Labs (MERL). He earned his Ph.D. from the Department of Electrical and Computer Engineering at the University of Maryland College Park in 2012, advised by Prof. Rama Chellappa. He received the R&D 100 Award for his robotic bin picking work in 2014. His street scene understanding paper was in the best paper finalist in the 2015 Robotics Science and System (RSS) conference. In CVPR 2018, he won the 1st place in both the domain adaptation for semantic segmentation competition and the optical flow estimation competition. In the recent years, his research focus is on generative image modeling. His work in this space include pix2pixHD, vid2vid, GauGAN/SPADE, UNIT, MUNIT, and FUNIT. His generative model work has been covered in various media outlets including the New York Times. His career goal is to enable machines human-like imagination capabilities.</p>

		<p>
			<a href="https://github.com/mingyuliutw" accesskey="6" title=""><img src="images/github.jpg" alt="" width="60" class="left" /></a>
			<a href="https://twitter.com/liu_mingyu" accesskey="6" title=""><img src="images/twitter.jpg" alt="" width="65" class="left" /></a>
			<a href="https://www.linkedin.com/in/mingyuliu/" accesskey="6" title=""><img src="images/linkedin.jpg" alt="" width="64" class="left"/></a>
		</p>
	</div>
	<p class="meta"></p>
</div>


<div id="latest-post" class="post">
	<h1>Research focus</h1>

	<table style="width:100%">
	<!-- SPADE -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/spade.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
	    	<h2><a href="https://github.com/NVlabs/SPADE">SPADE</a>:  
			Semantic Image Synthesis with Spatially-Adaptive Normalization (CVPR 2019) </h2>
			</h2>
		</th> 
    </tr>    
    <!-- VID2VID -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/vid2vid.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
	    	<h2><h2><a href="https://github.com/NVIDIA/vid2vid">vid2vid</a>: Video-to-Video Synthesis (NeurIPS 2018)</h2>
			</h2>
		</th> 
    </tr>	
    <!-- MUNIT -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/munit.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
			<h2><a href="https://github.com/NVlabs/MUNIT">MUNIT</a>: Multimodal unsupervised image-to-image translation (ECCV 2018)</h2>
			</h2>
		</th> 
    </tr>
    <!-- FastPhotoStyle -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/fast_photo_style.png" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
			<h2><a href="https://github.com/nvidia/fastphotostyle">FastPhotoStyle</a><br>
			A Closed-form Solution to Photorealistic Image Stylization (ECCV 2018)</h2>
			</h2>
		</th> 
    </tr>
    <!-- pix2pixHD -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/pix2pixHD.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
			<h2><a href="https://github.com/NVIDIA/pix2pixHD">pix2pixHD</a><br>
			High-res image synthesis and semantic manipulation (CVPR 2018)</h2>
			</h2>
		</th> 
    </tr>
    <!-- MoCoGAN -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/mocogan.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
		<h2><a href="https://github.com/sergeytulyakov/mocogan">MoCoGAN</a><br>
		Decomposing Motion and Content for Video Generation (CVPR 2018)</h2>
		</th> 
    </tr>        
    <!-- UNIT -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/unit.gif" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
			<h2><a href="https://github.com/mingyuliutw/UNIT">UNIT</a><br>
			Unsupervised image-to-image translation Network (NeurIPS 2017)</h2>
		</th> 
    </tr>
    <!-- Coupled GAN -->
	<tr>
	    <th>
	    	<div class="entry"><img src="gifs/cogan.png" alt="" width="480" class="left" />
	    </th>
	    <th style="text-align:left;vertical-align:top">
			<h2><a href="https://github.com/mingyuliutw/UNIT">Coupled GAN</a><br>
			Coupled Generative Adversarial Networks (NeurIPS 2016)<br>
			</h2>
		</th> 
    </tr>          
	</table>
</div>

<hr />
<div id= "awards">
<div id="latest-post" class="post"><h1><b>Award</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p><a href="http://bdd-data.berkeley.edu/wad-2018.html"> 1st place, Domain Adaptation for Semantic Segmentation Competition, WAD Challenge, CVPR 2018</a></h2>		
		</li>		
		<li>
		  <h2><p><a href="http://www.robustvision.net/leaderboard.php?benchmark=flow"> 1st place, Optical Flow Competition, Robust Vision Challenge, CVPR 2018</a></h2>		
		</li>	
		<li>
		  <h2><p> Outstanding Reviewer, <a href="http://cvpr2018.thecvf.com/program/reviewer_acknowledgements">CVPR 2018</b></a></h2>		
		</li>
		<li>
		  <h2><p> Pioneer Research Award, NVIDIA 2017, 2018</b></h2>		
		</li>
		<li>
		  <h2><p> NTECH Best Presenter Award, NVIDIA 2017</b></h2>		
		</li>
		<li>
		  <h2><p> CR&D Award, Mitsubishi Electric Research Labs (MERL) 2016</b></h2>		
		</li>			
		<li>
		  <h2><p> Best paper finalist 2015, <b><a href="http://www.roboticsfoundation.org/index.php/awards">Robotics Science and Systems (RSS) Conference 2015</a></b></h2>		
		</li>				  
		<li>		  
		  <h2><p>R&D 100 award 2014, <b><a href="http://www.rd100awards.com/">R&D Magazine</a></b></h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="service">
<div id="latest-post" class="post"><h1><b>Peer Review Effort</b></h1>
	<div class="entry">
	<ul>
		<li> 
			<h2>Conference reviewer: CVPR, ICCV, ECCV, NIPS, ICML, ICLR</h2>
		</li>
		<li> 
			<h2>Journal reviewer: TPAMI, IJCV, TIP, TMM, CVIU</h2>
		</li>
		<li> 
			<h2>Journal guess editor: IJCV, CVIU</h2>
		</li>	
		<li> 
			<h2>Area chair: ICCV, BMVC, WACV</h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="tutorial">
<div id="latest-post" class="post"><h1><b>Tutorial Effort</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2>ICIP 2019 Tutorial: Image-to-Image Translation</h2>
		</li>
		<li>
		  <h2>CVPR 2019 Tutorial: Deep Learning for Content Creation</h2>
		</li>		
		<li>
		  <h2>CVPR 2017 Tutorial: Theory and Applications of Generative Adversarial Networks, <a href="https://github.com/mingyuliutw/cvpr2017_gan_tutorial">[Site]</a></h2>
		</li>	
		<li>
		  <h2>ACCV 2016 Tutorial: Deep Learning for Vision Guided Language Generation and Image Generation, <a href="tutorial/accv2016_dl_tutorial/index.html">[Site]</a></h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="workshop">
<div id="latest-post" class="post"><h1><b>Workshop Effort</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2>CVPR 2019 Workshop: 4th New Trends in Image Restoration and Enhancement workshop and challenges</h2>
		</li>
		<li>
		  <h2>CVPR 2019 Workshop: AI City Challenge, <a href="https://www.aicitychallenge.org/">[Site]</a></h2>
		</li>			
		<li>
		  <h2>CVPR 2018 Workshop: AI City Challenge, <a href="https://www.aicitychallenge.org/">[Site]</a></h2>
		</li>
		</ul>
	</ul>	
	</div>
</div>	


<div id="footer">
	<p class="legal">&copy;2019 All Rights Reserved.</p>
</div>
</body>
</html>

