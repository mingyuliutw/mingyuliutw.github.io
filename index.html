<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : News Beat
Description: A fixed-width design suitable for small sites and blogs.
Version    : 1.0
Released   : 20071215

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!-- <rule name="Proxy">
  <match url="(.*)" />
  <action type="Rewrite" url="http://mingyuliu.net/{R:1}" />
</rule>	
<META HTTP-EQUIV="Rewrite" CONTENT="3;URL=http://mingyuliu.net"> -->
<!--<META HTTP-EQUIV="refresh" CONTENT="3;URL=https://sites.google.com/site/seanmingyuliu/">-->
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title><b>Ming-Yu Liu 劉洺堉</b></title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>
<body>
<div id="header">
	<h1><a href="#"><b>Ming-Yu Liu</b></a></h1>
</div>
<div id="menu">
	<ul>
		<li class=""><a href="index.html" accesskey="1" title="">About Me</a></li>
		<li><a href="publication.html" accesskey="2" title="">Publication</a></li>
		<li><a href="publication.html#patent" accesskey="4" title="">Patent</a></li>
		<li><a href="publication.html#tutorial" accesskey="5" title="">Tutorial</a></li>
		<li><a href="http://mingyuliu.blog" accesskey="6" title="">Research Blog</a></li>
		<li><a href="https://kungfu4mingyu.wordpress.com" accesskey="7" title="">Kung-Fu Blog</a></li>		
	</ul>
</div>
<hr />
<div id="latest-post" class="post">
	<div class="entry"><img src="images/mingyu_2016.jpg" alt="" width="200" class="left" />		
		<p><h2>Ming-Yu Liu joined Nvidia Research in 2016. He was a researcher at Mitsubishi Electric Research Labs (MERL) from 2012 to 2016. He received his Ph.D. from the Department of Electrical and Computer Engineering at the University of Maryland College Park in 2012. His early research work on object pose estimation contributed to development of the first commercial vision-based robotic bin-picking system for robotic assembly tasks, which was awarded the 100 most innovative technology products of the year by the R&D magazine in 2014. His robotics science and system (RSS) 2015 conference paper on street scene understanding was in the best paper finalist. Recently, his research focus shifted to deep generative models for image understanding and generation. His goal is to enable machines superhuman-like imagination capabilities.</p>
		<p><h2>Check out my new code release in <a href="https://github.com/mingyuliutw" accesskey="6" title="">GitHub</a>. Follow me on Twitter  <a href="https://twitter.com/liu_mingyu" accesskey="6" title="">Twitter</a>	

		<!---A copy of my resume can be found in <a href="resume/resume.pdf">link</a>. -->
		</h2></p>
	</div>
	<p class="meta"></p>
</div>

<div id="latest-post" class="post">
	<h1>Recent Research Focus</h1>
	<h2><a href="https://github.com/NVIDIA/pix2pixHD">pix2pixHD</a> for high-res image synthesis and semantic manipulation (arxiv 2017)</h2>
	<div class="entry"><img src="images/pix2pixHD.gif" alt="" width="720" class="left" />		
		</h2></p>
	</div>
	<p class="meta"></p>
	<br>
	<h2><a href="https://github.com/mingyuliutw/UNIT">CoupledGAN</a> for unsupervised image-to-image translation (NIPS 2016, NIPS 2017)<br>
		Left: input; <b>right: machine-generated</b></h2>
	<div class="entry"><img src="images/UNIT.gif" alt="" width="720" class="left" />		
		</h2></p>
	</div>
	<p class="meta"></p>
	<br>
	<h2><a href="https://github.com/sergeytulyakov/mocogan">MoCoGAN</a> for video generation (NIPS 2017 workshop)</h2>
	<div class="entry"><img src="images/mocogan.gif" alt="" width="720" class="left" />		
		</h2></p>
	</div>
	<p class="meta"></p>
</div>


<hr />
<div id= "research">
<div id="latest-post" class="post"><h1><b>Other Research</b></h1>
	<div class="entry">
	<ul>
		<li><h2><a href="https://github.com/mingyuliutw/Research/blob/master/SemanticSegmentation.md">Semantic Segmentation</a></h2></li>
		<li><h2><a href="https://github.com/mingyuliutw/Research/blob/master/RoboticBinPicking.md">Robotic Bin-Picking</a></h2></li>
	</ul>
	</ul>	
	</div>
</div>	

<!-- <hr />
<div id="education">
<div id="latest-post" class="post"><h1><b>Education</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p>PhD, Electrical&Computer Engineering, University of Maryland College Park, Advisor: <a href="http://www.umiacs.umd.edu/~rama">Rama Chellappa</a>, 2006-2012</h2>
		</li>
		<li>
		  <h2><p>BA, National Chiao Tung University, Taiwan, 1999-2003</h2>		  
		</li>
		</ul>
	</ul>	
	</div>
</div>
</div> -->
<!---
<hr />
<div id="latest-post" class="post"><h1><b>Experiences</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p>Senior Research Scientist (Level 4), <a href="https://research.nvidia.com">Nvidia Research</a>, Santa Clara, CA, USA, 2017.09-now</h2>
		</li>	
		<li>
		  <h2><p>Senior Research Scientist (Level 4), <a href="https://research.nvidia.com">Nvidia Research</a>, Santa Clara, CA, USA, 2016.08-2017.09</h2>
		</li>		
		<li>
		  <h2><p>Principal Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2015.04-2016.08</h2>
		</li>	
		<li>
		  <h2><p>Member Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2013.09-2015.03</h2>
		</li>
		<li>
		  <h2><p>Visiting Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2012.02-2013.08</h2>
		</li>		
		<li>
		  <h2><p>Software Engineering Intern, <a href="http://www.intel.com">Intel</a>, Taiwan branch, 2005-2006</h2>
		</li>
		<li>
		  <h2><p>Army officer, second lieutenant, Taiwan, 2003-2005</h2>
		</li>				
		</ul>
	</ul>	
	</div>
</div>	
-->

<hr />
<div id= "awards">
<div id="latest-post" class="post"><h1><b>Awards</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p> NTECH Best Presenter Award, NVIDIA 2017</b></h2>		
		</li>
		<li>
		  <h2><p> CR&D Award, MERL 2016</b></h2>		
		</li>			
		<li>
		  <h2><p> Best paper finalist 2015, <b><a href="http://www.roboticsfoundation.org/index.php/awards">Robotics Science and Systems (RSS) Conference 2015</a></b></h2>		
		</li>				  
		<li>		  
		  <h2><p>R&D 100 award 2014, <b><a href="http://www.rd100awards.com/">R&D Magazine</a></b></h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="service">
<div id="latest-post" class="post"><h1><b>Public Service</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2>Reviewer: NIPS, CVPR, ECCV, ICCV, ICLR, IEEE TPAMI, IEEE TIP, IEEE SPL, CVIU, NSF proposal
		</li>
		<li>
		  <h2>Area Chair: WACV
		</li>					
	</ul>	
	</div>
</div>	

<hr />
<div id="media">
<div id="latest-post" class="post"><h1><b>Media Coverage</b></h1>
	<div class="entry">
	<h2>Unsupervised Image-to-Image translation
	<ul>
		<li><a href="https://www.theverge.com/2017/12/5/16737260/ai-image-translation-nvidia-data-self-driving-cars">The Verge: "Nvidia uses AI to make it snow on streets that are always sunny."</a>
		</li>		
		<li><a href="https://www.technologyreview.com/the-download/609667/nvidias-tag-teaming-ais-imagine-night-as-day-and-house-cats-as-tigers/">MIT Technology Review: "Nvidia’s Tag-Teaming AIs Imagine Night as Day, and House Cats as Tigers"</a>
		</li>
		<li><a href="https://thenextweb.com/artificial-intelligence/2017/12/04/nvidias-new-ai-creates-disturbingly-convincing-fake-videos/">The Next Web: "Nvidia’s new AI creates disturbingly convincing fake videos"</a>
		</li>
		<li><a href="http://www.zdnet.com/article/nvidia-looks-to-reduce-ai-training-material-through-imagination/#ftag=RSSbaffb68">ZDNet "Nvidia looks to reduce AI training material through 'imagination'"</a>
		</li>
		<li><a href="http://it.sohu.com/20171006/n516267266.shtml">Sohu technology news "超级变变变：喵星人汪星人还有街景神奇变身"</a>
		</li>				
	</ul>	
	<h2>pix2pixHD
	<ul>
		<li><a href="http://www.sohu.com/a/208157474_473283">Sohu technology news "条件GAN高分辨率图像合成与语义编辑pix2pixHD"</a>
		</li>
		<li><a href="https://www.inverse.com/article/39018-these-neutral-networks-can-generate-realistic-photos">Inverse.com</a>
		</li>					
	</ul>
	</div>
</div>	


<div id="footer">
	<p class="legal">&copy;2017 All Rights Reserved.</p>
</div>
</body>
</html>

