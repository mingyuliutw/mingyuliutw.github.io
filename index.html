<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HMZ4KTHSR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HMZ4KTHSR');
</script>
	
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Ming-Yu Liu 劉洺堉</title>
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>
<body>
<div id="header">
	<h1><a href="#"><b>Ming-Yu Liu 劉洺堉</b></a></h1>
</div>
</br>
<div id="menu">
	<ul>
        <li class=""><a href="index.html" accesskey="1" title="">Home</a></li>
        <li><a href="publication.html" accesskey="3" title="">Publication</a></li>
    </ul>
</div>
<hr />
<div id="latest-post" class="post">
	<div class="entry">
	<h2>		
	<table>	
	<tr valign="top">
	<td>
		<img src="images/gtc_gaugan.jpg" alt="" width="400" class="left"/>
	</td>
	<td>
		Ming-Yu Liu leads a research team focusing on generative models and content creation at NVIDIA Research. Before that, he was a distinguished research scientist at NVIDIA. His research focuses on deep generative models and their applications on content creation. His ambition is to enable machine super-human imagination capability so that machines can better assist people in creating content and expressing themselves. Liu likes to put his research into people’s daily lives --- and <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas/GauGAN</a> and <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> are two products enabled by his research. He also strives to make the research community better and frequently serves as an area chair for various top-tier AI conferences, including NeurIPS, ICML, ICLR, CVPR, ICCV, and ECCV, as well as organize tutorials and workshops in these conferences. Empowered by many, Liu has won several major awards in his field, including winning a SIGGRAPH Best in Show award two times.</br></br>

		Prior to NIVIDA, he was a Principal Research Scientist with Mitsubishi Electric Research Laboratories (MERL). He received his Ph.D. degree from the University of Maryland, College Park, MD, USA, in 2012, advised by <a href="https://scholar.google.com/citations?user=L60tuywAAAAJ&hl=en">Prof. Rama Chellappa</a>.
		</br></br>

		<a href="https://github.com/mingyuliuthttps://scholar.google.com/citations?user=y-f-MZgAAAAJ&hl=enw" accesskey="6" title=""><img src="images/scholar.jpg" alt="" width="40" class="left" /></a>
		<a href="https://github.com/mingyuliutw" accesskey="6" title=""><img src="images/github.jpg" alt="" width="40" class="left" /></a>
		<a href="https://twitter.com/liu_mingyu" accesskey="6" title=""><img src="images/twitter.jpg" alt="" width="43" class="left" /></a>
		<a href="https://www.linkedin.com/in/mingyuliu/" accesskey="6" title=""><img src="images/linkedin.jpg" alt="" width="42" class="left"/></a>
	</td>
	</tr>
	</table>
	</h2>

			
	</div>
	<p class="meta"></p>
</div>

<hr />
<div id= "award">
<div id="latest-post" class="post"><h2><b>Awards</b></h2>
	<div class="entry">
	<h3>
	<ul>
		<li>
			<p><a href="https://twitter.com/siggraph/status/1425261704678682626?s=20">Best in Show Award , SIGGRAPH Real-Time-Live 2021</a>
		</li>				
		<li>
			<p><a href="https://www.forbes.com/sites/kenrickcai/2021/01/04/forbes-ai-awards-2020-meet-gpt-3-the-computer-program-that-can-write-an-op-ed/?sh=6866ea0b93a7">Most Disruptive Inventor Award, Forbes 2020</a>
		</li>
		<li>
			<p><a href="https://www.popsci.com/story/technology/best-of-whats-new-2019/#">Best of What's New Award, Popular Science Magazine 2019</a>
		</li>			
		<li>
			<p><a href="https://s2019.siggraph.org/conference/programs-events/real-time-live/">Best in Show Award and Audience Choice Award, SIGGRAPH Real-Time-Live 2019</a>
		</li>			
		<li>
			<p><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjChuizobjwAhUkJDQIHV8MDUEQFjAAegQIBBAD&url=https%3A%2F%2Fcvpr2019.thecvf.com%2Ffiles%2FCVPR%25202019%2520-%2520Welcome%2520Slides%2520Final.pdf&usg=AOvVaw20JOysDo6G5gvCa_k8Q4t9">Best Paper Finalist, CVPR 2019</a>
		</li>			
		<li>
		    <p> 1st place, Domain Adaptation for Semantic Segmentation Competition, WAD Challenge, CVPR 2018
		</li>		
		<li>
		    <p> 1st place, Optical Flow Competition, Robust Vision Challenge, CVPR 2018
		</li>	
		<li>
		    <p> Outstanding Reviewer, CVPR 2018
		</li>
		<li>
		    <p> Pioneer Research Award, NVIDIA 2017, 2018
		</li>
		<li>
		    <p> NTECH Best Presenter Award, NVIDIA 2017
		</li>
		<li>
		    <p> CR&D Award, Mitsubishi Electric Research Labs (MERL) 2016
		</li>			
		<li>
		    <p> Best paper finalist, Robotics Science and Systems (RSS) Conference 2015
		</li>				  
		<li>		  
		    <p><a href="https://www.mitsubishielectric.com/news/2014/0806.html">R&D 100 award, R&D Magazine 2014</a></h3>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	



<hr />
<div id="service">
<div id="latest-post" class="post"><h2><b>Research community service</b></h2>
	<div class="entry">
	<ul>
		<li> 
			<h3>Conference Program Chair: WACV (2020)</h3>
		</li>			
		<li> 
			<h3>Conference Area Chair: NeurIPS (2020, 2021, 2022), ICML (2021, 2022), ICLR (2021, 2022), CVPR (2020, 2022), ICCV (2019), ECCV (2020), BMVC (2019), WACV (2019)</h3>
		</li>		
		<li> 
			<h3>Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR</h3>
		</li>
		<li> 
			<h3>Journal Reviewer: TPAMI, IJCV, TIP, TMM, CVIU</h3>
		</li>
		<li> 
			<h3>Journal guess editor: IJCV (Special Issue on GANs)</h3>
		</li>	
		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="tutorial">
<div id="latest-post" class="post"><h2><b>Co-hosted Tutorials</b></h2>
	<div class="entry">
	<ul>
		<li>
		  <h3><a href="https://nvlabs.github.io/iccv2019-mixed-precision-tutorial/">[Site]</a> ICCV 2019 Tutorial on Accelerating Computer Vision with Mixed Precision</h3>
		</li>		
		<li>
		  <h3><a href="https://mingyuliutw.github.io/icip2019-image-translation-tutorial/index.html">[Site]</a> ICIP 2019 Tutorial: Image-to-Image Translation</h3>
		</li>
		<li>
		  <h3><a href="https://nvlabs.github.io/dl-for-content-creation/">[Site]</a> CVPR 2019 Tutorial: Deep Learning for Content Creation</h3>
		</li>
		<li>
		  <h3><a href="https://github.com/mingyuliutw/cvpr2017_gan_tutorial">[Site]</a> CVPR 2017 Tutorial: Theory and Applications of Generative Adversarial Networks</h3>
		</li>	
		<li>
		  <h3><a href="tutorial/accv2016_dl_tutorial/index.html">[Site]</a> ACCV 2016 Tutorial: Deep Learning for Vision Guided Language Generation and Image Generation</h3>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="workshop">
<div id="latest-post" class="post"><h2><b>Co-hosted Workshops</b></h2>
	<div class="entry">
	<ul>
		<li>
		  <h3><a href="https://visual.cs.brown.edu/aicc2020/">[Site]</a> CVPR 2021 Workshop: Content Creation</h3>
		</li>		
		<li>
		  <h3><a href="https://visual.cs.brown.edu/aicc2020/">[Site]</a> CVPR 2020 Workshop: Content Creation</h3>
		</li>		
		<li>
		  <h3><a href="https://sites.google.com/berkeley.edu/iccv-2019-image-and-video-syn">[Site]</a> ICCV 2019 Workshop: Image and Video Synthesis: How, Why and "What if"?</h3>
		</li>	
		<li>
		  <h3><a href="https://www.vision.ee.ethz.ch/aim19/">[Site]</a> ICCV 2019 Workshop: Advances in Image Manipulation workshop and challenges on image and video manipulation</h3>
		</li>		
		<li>
		  <h3><a href="https://www.vision.ee.ethz.ch/ntire19/">[Site]</a> CVPR 2019 Workshop: 4th New Trends in Image Restoration and Enhancement workshop and challenges</h3>
		</li>
		<li>
		  <h3><a href="https://www.aicitychallenge.org/">[Site]</a>CVPR 2019 Workshop: AI City Challenge</h3>
		</li>			
		<li>
		  <h3><a href="https://www.aicitychallenge.org/">[Site]</a> CVPR 2018 Workshop: AI City Challenge</h3>
		</li>
		</ul>
	</ul>	
	</div>
</div>	


<div id="footer">
	<p class="legal">&copy;2021 All Rights Reserved.</p>
</div>
</body>
</html>

