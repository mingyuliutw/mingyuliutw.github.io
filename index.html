<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : News Beat
Description: A fixed-width design suitable for small sites and blogs.
Version    : 1.0
Released   : 20071215

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!-- <rule name="Proxy">
  <match url="(.*)" />
  <action type="Rewrite" url="http://mingyuliu.net/{R:1}" />
</rule>	
<META HTTP-EQUIV="Rewrite" CONTENT="3;URL=http://mingyuliu.net"> -->
<!--<META HTTP-EQUIV="refresh" CONTENT="3;URL=https://sites.google.com/site/seanmingyuliu/">-->
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title><b>Ming-Yu Liu 劉洺堉</b></title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>
<body>
<div id="header">
	<h1><a href="#"><b>Ming-Yu Liu</b></a></h1>
</div>
<div id="menu">
	<ul>
		<li class=""><a href="index.html" accesskey="1" title="">About Me</a></li>
		<li><a href="#publication" accesskey="2" title="">Publication</a></li>
		<li><a href="#research" accesskey="3" title="">Research</a></li>
		<li><a href="#patent" accesskey="4" title="">Patent</a></li>
		<li><a href="#tutorial" accesskey="5" title="">Tutorial</a></li>
		<li><a href="http://mingyuliu.blog" accesskey="7" title="">Research Blog</a></li>
		<li><a href="https://kungfu4mingyu.wordpress.com" accesskey="8" title="">Kung-Fu</a></li>		
	</ul>
</div>
<hr />
<div id="latest-post" class="post">
	<div class="entry"><img src="images/mingyu_2016.jpg" alt="" width="200" class="left" />		
		<p><h2>Ming-Yu Liu is a researcher at Nvidia Research. Prior to joining NVIDIA, he was a researcher at Mitsubishi Electric Research Labs (MERL). He received his Ph.D. from the Department of Electrical and Computer Engineering at the University of Maryland College Park in 2012. His research interests are on computer vision and deep learning. His early research work on object pose estimation contributed to development of the first commercial vision-based robotic bin-picking system for robotic assembly tasks, which was awarded the 100 most innovative technology products of the year by the R&D magazine in 2014. He is a recipient of a paper award from the robotics science and system (RSS) 2015 conference for his street scene understanding work. Recently, his research focus shifted to deep generative models for image understanding and generation. His goal is to enable machines superhuman-like imagination capabilities. </p>
		<p>Check out my new code release in <a href="https://github.com/mingyuliutw" accesskey="6" title="">GitHub</a>. Follow me on Twitter  <a href="https://twitter.com/liu_mingyu" accesskey="6" title="">Twitter</a>	

		<!---A copy of my resume can be found in <a href="resume/resume.pdf">link</a>. -->
		</h2></p>
	</div>
	<p class="meta"></p>
</div>

<hr />
<div id="news">
<div id="latest-post" class="post"><h1><b>News</b></h1>
	<div class="entry">
	<ul>
		<li><h2>07-26-2017: Gave a tutorial on GANs in CVPR 2017. <a href="https://github.com/mingyuliutw/cvpr2017_gan_tutorial">[Slides]</a> </h2></li>
		<li><h2>07-20-2017: CoVAE-GAN code released. <a href="https://github.com/mingyuliutw/UNIT">[Code]</a> </h2></li>
		<li><h2>04-24-2017: One paper accepted by IJCAI</h2></li>
		<!-- 
		<li><h2>04-10-2017: A PyTorch implementation of the coupled generative adversarial networks is released in GitHub via <a href="https://github.com/mingyuliutw/CoGAN_PyTorch">[CoGAN_PyTorch]</a>.</li>				
		<li><h2>03-20-2017: One paper accepted by ICLR Workshop</h2></li>	
		<li><h2>03-02-2017: Two papers accepted by CVPR</h2></li>	
		<li><h2>11-24-2016: Presented a tutorial on GAN and a paper on small object detection in ACCV</h2></li>		
		<li><h2>09-22-2016: An implementation of the coupled generative adversarial networks is released in GitHub via <a href="https://github.com/mingyuliutw/CoGAN">[CoGAN]</a>. For more details, please refer to our NIPS paper.</h2></li>		
		<li><h2>08-29-2016: Joined Nvidia Research</h2></li>		
		<li><h2>08-19-2016: Left Mitsubishi Electric Research Labs (MERL)</h2></li>				 
		-->
		</ul>
	</ul>	
	</div>
</div>	

<hr />



<hr />
<div id= "awards">
<div id="latest-post" class="post"><h1><b>Awards</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p> Best paper finalist 2015, <b><a href="http://www.roboticsfoundation.org/index.php/awards">Robotics Science and Systems (RSS) Conference 2015</a></b></h2>		
		</li>				  
		<li>		  
		  <h2><p>R&D 100 award 2014, <b><a href="http://www.rd100awards.com/">R&D Magazine</a></b></h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id= "research">
<div id="latest-post" class="post"><h1><b>Research</b></h1>
	<div class="entry">
	<ul>
		<li><h2><a href="https://github.com/mingyuliutw/GenerativeModeling/tree/master">Generative Modeling</a></h2></li>
		<li><h2><a href="https://github.com/mingyuliutw/SemanticSegmentation/tree/master">Semantic Segmentation</a></h2></li>
		<li><h2><a href="https://github.com/mingyuliutw/RobotCell/tree/master">Robotic Bin-Picking</a></h2></li>		
	</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id = "publication">
<div id="latest-post" class="post"><h1><b>Publication</b></h1>
	<div class="entry" id = "publications">
	<ul><h2><b>2017</b></h2>
		<ul>
		    <li>
				<h2><b><p><a href="https://arxiv.org/abs/1703.06748">MoCoGAN: Decomposing Motion and Content for Video Generation</a></b></br>
				Sergey Tulyakov, <b>Ming-Yu Liu</b>, Xiaodong Yang, Jan Kautz</br>
				arXiv preprint arXiv:1707.04993</br>
				<a href="https://github.com/sergeytulyakov/mocogan">[Code]</a>
				</p></h2>
			</li>	
      		<li>
				<h2><b><p><a href="https://arxiv.org/abs/1703.06748">Tactics of Adversarial Attack on Deep Reinforcement Learning Agents</a></b></br>
				Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, <b>Ming-Yu Liu</b>, Min Sun </br>
				International Joint Conference on Artificial Intelligence (IJCAI), 2017 Melbourne, Australia </br>
				and Workshop on International Conference on Learning Representation (ICLR), 2017, Toulon, France </br>
				<a href="http://yclin.me/adversarial_attack_RL">[Project]</a>
				</p></h2>
			</li>			
			<li>
				<h2><b><p><a href="https://arxiv.org/abs/1703.00848">Unsupervised Image-to-Image Translation Networks</a></b></br>
				<b>Ming-Yu Liu</b>, Thomas Breuel, and Jan Kautz</br>
				arXiv preprint arXiv:1703.00848</br>
				<a href="https://github.com/mingyuliutw/UNIT">[Code]</a>
				</p></h2>
			</li>				
      		<li>
				<h2><b><p><a href="https://arxiv.org/abs/1705.01759">Deep 360 Pilot: Learning a Deep Agent for Piloting through 360 Sports Videos</a></b></br>
				Hou-Ning Hu*, Yen-Chen Lin*, <b>Ming-Yu Liu</b>, Hsien-Tzu Cheng, Stanley Chang, Min Sun </br>
				Conference on Computer Vision and Pattern Recognition (CVPR) (Oral), 2017, Honolulu, Hawaii
				</p></h2>
			</li>			
			<li>
				<h2><b><p><a href="https://arxiv.org/abs/1705.09759">CASENet: Deep Category-Aware Semantic Edge Detection</a></b></br>
				Zhiding Yu, Chen Feng, <b>Ming-Yu Liu</b>, Srikumar Ramalingam</br>
				Conference on Computer Vision and Pattern Recognition (CVPR), 2017, Honolulu, Hawaii
				</p></h2>
			</li>  			
			<li>
				<h2><b><p><a href="https://arxiv.org/abs/1702.01478">Attentional Network for Visual Object Detection</a></b></br>
				Kota Hara, <b>Ming-Yu Liu</b>,  Oncel Tuzel, and Amir-massoud Farahmand</br>
				arXiv preprint arXiv:1702.01478
				</p></h2>
			</li>			
			<li>
				<h2><b><p><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwiIlsv5rM3UAhUBSmMKHQP3CqkQFggoMAA&url=https%3A%2F%2Fwww.merl.com%2Fpublications%2Fdocs%2FTR2017-034.pdf&usg=AFQjCNGc-X6w77YpTRje4RqQUoUPyOqxKA&sig2=TQf3_lU8pQbKjA3J5g9rIw">Deep Active Learning for Civil Infrastructure Defect Detection and Classification</a></b></br>
				Chen Feng, <b>Ming-Yu Liu</b>, Chieh-Chi Kao, and Teng-Yok Lee</br>
				International Workshop on Computing in Civil Engineering (IWCCE), 2017, Seatle, Washington
				</p></h2>
			</li>		
		</ul>
	</ul>		
	<ul><h2><b>2016</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://arxiv.org/abs/1606.07536">Coupled Generative Adversarial Networks</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel</br>
				Neural Information Processing Systems (NIPS), 2016, Barcelona, Spain,</br>
				<a href="https://github.com/mingyuliutw/CoGAN">[Code]</a></p></h2>
			</li>		
		</ul>		
		<ul>
			<li>
				<h2><b><p><a href="https://merl.com/publications/docs/TR2016-144.pdf">R-CNN for Small Object Detection</a></b></br>
				Chenyi Chen, <b>Ming-Yu Liu</b>, Oncel Tuzel, Jianxiong Xiao</br>
				Asian Conference on Computer Vision  (ACCV), 2016, Taipei, Taiwan
				</p></h2>
			</li>		
		</ul>				
		<ul>
			<li>
				<h2><b><p><a href="http://ravitejav.weebly.com/uploads/2/4/7/2/24725306/segmentation.pdf">Gaussian Conditional Random Field Network for Semantic Segmentation</a></b></br>
				Raviteja Vemulapalli, Oncel Tuzel, <b>Ming-Yu Liu</b>, Rama Chellappa</br>
				Conference on Computer Vision and Pattern Recognition (CVPR) (Spotlight), 2016, Las Vegas, Nevada, </br>
				</p></h2>
			</li>		
		</ul>		
		<ul>
			<li>
				<h2><b><p><a href="http://arxiv.org/pdf/1511.04067.pdf">Deep Gaussian Conditional Random Field Network: A Model-based Deep Network for Discriminative Denoising</a></b></br>
				Raviteja Vemulapalli, Oncel Tuzel, <b>Ming-Yu Liu</b></br>
				Conference on Computer Vision and Pattern Recognition (CVPR), 2016, Las Vegas, Nevada, </br>
				</p></h2>
			</li>		
		</ul>	

		<ul>
			<li>
				<h2><b><p><a href="http://arxiv.org/abs/1601.01750">Learning to Remove Multipath Distortions in Time-of-Flight Range Images for a Robotic Arm Setup</a></b></br>
				Kilho Son, <b>Ming-Yu Liu</b>, Yuichi Taguchi</br>
				IEEE International Conference on Robotics and Automation (ICRA), 2016, Stockholm, Sweden</br><a href="https://github.com/kilho/learning_tof">[Dataset]</a>
				</p></h2>
			</li>		
		</ul>	
		<ul>
			<li>
				<h2><b><p><a href="http://arxiv.org/abs/1502.05689">Unsupervised Network Pretraining via Encoding Human Design</a></b></br>
				<b>Ming-Yu Liu</b>, Arun Mallya, Oncel Tuzel, Xi Chen</br>
				IEEE Winter Conference on Computer Vision (WACV), 2016, New York, USA
				</p></h2>
			</li>		
		</ul>
	</ul>	
	<ul><h2><b>2015</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://www.roboticsproceedings.org/rss11/p25.html">Layered Interpretation of Street View Images</a></b></br>
				<b>Ming-Yu Liu</b>, Shuoxin Lin, Srikumar Ramalingam, Oncel Tuzel</br>
				Robotics: Science and Systems Conference (RSS) (Best paper finalist), 2015, Rome, Italy
				</p></h2>
			</li>		
		</ul>
	</ul>	
	<ul><h2><b>2014</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://papers.nips.cc/paper/5282-recursive-context-propagation-network-for-semantic-scene-labeling.pdf">Recursive Context Propagation Network for Semantic Scene Labeling</a></b></br>
				Abhishek Sharma, Oncel Tuzel, <b>Ming-Yu Liu</b></br>
				Neural Information Processing Systems (NIPS), 2014, Montreal, Canada
				</p></h2>
			</li>	
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2014-078.pdf">Learning to Rankd 3D Features</a></b></br>
				Oncel Tuzel, <b>Ming-Yu Liu</b>, Yuichi Taguchi, Arvind Raghunathan</br>
				European Conference on Computer Vision (ECCV), 2014, Zurich, Switzerland 
				</p></h2>
			</li>				
		</ul>
	</ul>
	<ul><h2><b>2013</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2013-042.pdf">Joint Geodesic Upsampling of Depth Images</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Yuichi Taguchi</br>
				Conference on Computer Vision and Pattern Recognition (CVPR), 2013, Portland, Oregon, USA</br><a href="https://github.com/mingyuliutw/jgu.git">[Results]</a><a href="http://www.merl.com/research/license/">[Code]</a></p></h2></h2>
			</li>	
			<li>
				<h2><b><p><a href="papers/liu_entropy_tpami14.pdf">Entropy Rate Clustering: Cluster Analysis via Maximizing a Submodular Function Subject to a Matroid Constraint</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Srikumar Ramalingam, Rama Chellappa</br>
				IEEE Transaction on Pattern Analysis and Machine Intelligence (TPAMI), 2013 </br><a href="papers/liu_entropy_proofs_tpami14.pdf">[Proofs]</a>
				<a href="https://github.com/mingyuliutw/ers.git">[Code]</a></p></h2>
			</li>				
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2013-055.pdf">Model-based Vehicle Pose Estimation and Tracking in Videos Using Random Forests</a></b></br>
				Michael Hodlmoser, Branislav Micusik, Marc Pollefeys, <b>Ming-Yu Liu</b>, Martin Kampel</br>
				3DV 2013, Seattle, Washington, USA
				</p></h2>
			</li>		
		</ul>
	</ul>
	<ul><h2><b>2012</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2012-007.pdf">Fast Object Localization and Pose Estimation in Heavy Clutter for Robotic Bin Picking</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Ashok Veeraraghavan, Yuichi Taguchi, Tim K. Marks, Rama Chellappa</br>
				International Journal of Robotics Research (IJRR) 2012
				</br><a href="https://github.com/mingyuliutw/fdcm.git">[Code]</a></p></h2>
			</li>	
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2012-032.pdf">Voting-Based Pose Estimation for Robotic Assembly Using a 3D Sensor</a></b></br>
				Changhyun Choi, Yuichi Taguchi, Oncel Tuzel, <b>Ming-Yu Liu</b>, Srikumar Ramalingam</br>
				International Conference on Robotics and Automation (ICRA), 2012, St. Paul, Minnesota, USA
				</p></h2>
			</li>				
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2012-092.pdf">A Grassmann Manifold-based Domain Adaptation Approach</a></b></br>
				Jingjing Zheng, <b>Ming-Yu Liu</b>, Rama Chellappa, P Jonathan Phillips</br>
				International Conference on Pattern Recognition (ICPR) (Oral), 2012, Tsukuba Science City, Japan
				</p></h2>
			</li>		
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2012-081.pdf">Classification and Pose Estimation of Vehicles in Videos by 3D Modeling within Discrete-Continuous Optimization</a></b></br>
				Michael Hödlmoser, Branislav Micusik, <b>Ming-Yu Liu</b>, Marc Pollefeys, Martin Kampel</br>
				3DV 2012, Zurich, Switzerland
				</p></h2>
			</li>			
		</ul>
	</ul>
	<ul><h2><b>2011</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2011-035.pdf">Entropy Rate Superpixel Segmentation</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Srikumar Ramalingam, Rama Chellappa</br>
				Conference on Computer Vision and Pattern Recognition (CVPR), 2011, Colorado Springs, Colorado, USA</br><a href="https://github.com/mingyuliutw/ers.git">[Code]</a>
				</p></h2>
			</li>			
		</ul>
	</ul>		
	<ul><h2><b>2010</b></h2>
		<ul>
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2010-045.pdf">Fast Directional Chamfer Matching</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Ashok Veeraraghavan, Rama Chellappa</br>
				Conference on Computer Vision and Pattern Recognition (CVPR), 2010, San Francisco, California, USA </br><a href="https://github.com/mingyuliutw/fdcm.git">[Code]</a>
				</p></h2>
			</li>			
			<li>
				<h2><b><p><a href="http://www.merl.com/publications/docs/TR2010-024.pdf">Pose Estimation in Heavy Clutter Using a Multi-Flash Camera</a></b></br>
				<b>Ming-Yu Liu</b>, Oncel Tuzel, Ashok Veeraraghavan, Rama Chellappa, Amit Agrawal, Haruhisa Okuda</br>
				International Conference on Robotics and Automation (ICRA), 2010, Anchorage, Alaska, USA </br><a href="https://github.com/mingyuliutw/fdcm.git">[Code]</a>
				</p></h2>
			</li>					
		</ul>
	</ul>		
	</div>
</div>	
</div>

<hr />
<div id="patent">
<div id="latest-post" class="post"><h1><b>Patents granted</b></h1>
	<div class="entry">
	<ul>
		<li><h2><p> US 9,633,274: Method and system for denoising images using deep Gaussian conditional random field network</p></h2></li>
		<li><h2><p> US 9,558,268: Method for semantically labeling an image of a scene using recursive context propagation</p></h2></li>
		<li><h2><p> US 8,428,363: Method for segmenting images using superpixels and entropy rate clustering</p></h2></li>
		<li><h2><p> US 8,983,177: Method for increasing resolutions of depth images</p></h2></li>
		<li><h2><p> US 8,908,913: Voting-based pose estimation for 3D sensors</p></h2></li>
		<li><h2><p> US 9,195,904: Method for detecting objects in stereo images</p></h2></li>		
		<li><h2><p> US 9,280,827: Method for determining object poses using Weighted Features</p></h2></li>			
		<li><h2><p><a href="https://patents.google.com/?assignee=Mitsubishi+Electric&inventor=Ming-Yu+Liu">My MERL patents</a></p></h2></li>
	</ul>	
	</div>
</div>

<hr />
<div id="education">
<div id="latest-post" class="post"><h1><b>Education</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p>PhD, Electrical&Computer Engineering, University of Maryland College Park, Advisor: <a href="http://www.umiacs.umd.edu/~rama">Rama Chellappa</a>, 2006-2012</h2>
		</li>
		<!--
		<li>
		  <h2><p>BA, National Chiao Tung University, Taiwan, 1999-2003</h2>		  
		</li>
		-->
		</ul>
	</ul>	
	</div>
</div>
</div>
<!---
<hr />
<div id="latest-post" class="post"><h1><b>Experiences</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2><p>Senior Research Scientist, <a href="https://research.nvidia.com">Nvidia Research</a>, Santa Clara, CA, USA, 2016.08-now</h2>
		</li>		
		<li>
		  <h2><p>Principal Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2015.04-2016.08</h2>
		</li>	
		<li>
		  <h2><p>Member Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2013.09-2015.03</h2>
		</li>
		<li>
		  <h2><p>Visiting Research Scientist, <a href="http://www.merl.com">Mitsubishi Electric Research Labs (MERL)</a>, Cambridge, MA, USA, 2012.02-2013.08</h2>
		</li>		
		<li>
		  <h2><p>Software Engineering Intern, <a href="http://www.intel.com">Intel</a>, Taiwan branch, 2005-2006</h2>
		</li>
		<li>
		  <h2><p>Army officer, second lieutenant, Taiwan, 2003-2005</h2>
		</li>				
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="code">
<div id="latest-post" class="post"><h1><b>Open Source</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2>Joint image distribution learning based on generative adversarial networks: [Coupled Generative Adversarial Networks <a href="https://github.com/mingyuliutw/CoGAN">(Caffe)</a><a href="https://github.com/mingyuliutw/CoGAN_PyTorch">(PyTorch)]</a></h2>
		</li>		
		<li>
		  <h2>Shape template matching: <a href="https://github.com/mingyuliutw/fdcm.git">[Fast directional chamfer matching algorithm]</a></h2>
		</li>	
		<li>
		  <h2>Superpixel segmentation: <a href="https://github.com/mingyuliutw/ers.git">[Entropy rate superpixel segmentation algorithm]</a></h2>
		</li>		
		<li>
		  <h2>Depth superresolution: <a href="http://www.merl.com/research/license/">[Joint geodesic depth upsamplsing algorithm]</a></h2>
		</li>
		<li>
		  <h2>Dataset for studying multi-path distortions in TOF range images: <a href="https://github.com/kilho/learning_tof">[TOF multi-path distortion dataset]</a></h2>
		</li>		
		
		</ul>
	</ul>	
	</div>
</div>	

-->

<hr />
<div id="tutorial">
<div id="latest-post" class="post"><h1><b>Tutorial</b></h1>
	<div class="entry">
	<ul>
		<li>
		  <h2>CVPR2017: Theory and Applications of Generative Adversarial Networks, <a href="https://github.com/mingyuliutw/cvpr2017_gan_tutorial">[Site]</a></h2>
		</li>	
		<li>
		  <h2>ACCV2016: Deep Learning for Vision Guided Language Generation and Image Generation, <a href="tutorial/accv2016_dl_tutorial/index.html">[Site]</a></h2>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<div id="footer">
	<p class="legal">&copy;2016 All Rights Reserved.</p>
</div>
</body>
</html>

