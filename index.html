<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Ming-Yu Liu 劉洺堉</title>
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>
<body>
<div id="header">
	<h1><a href="#"><b>Ming-Yu Liu 劉洺堉</b></a></h1>
</div>
</br>
<div id="menu">
	<ul>
        <li class=""><a href="index.html" accesskey="1" title="">Home</a></li>
        <li><a href="publication.html" accesskey="3" title="">Publication</a></li>
    </ul>
</div>
<hr />
<div id="latest-post" class="post">
	<div class="entry">
	<h2>		
	<table>	
	<tr valign="top">
	<td>
		<img src="images/gtc_gaugan.jpg" alt="" width="400" class="left"/>
	</td>
	<td>
		I am a Distinguished Research Scientist and a Director of Research at NVIDIA. My research focus is on deep generative models and their applications. I want to enable machine super-human imagination capability so that they can better assist us in creating content and expressing ourselves. I like to put my research into people’s hands. <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas/GauGAN</a> and <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> are two products enabled by my research. I consider making the research community better part of my mission. I frequently serve as an area chair for various top-tier AI conferences, including NeurIPS, ICML, ICLR, CVPR, ICCV, and ECCV, as well as organize tutorials and workshops in my field. Empowered by many, I have won several major awards in my field, including winning the SIGGRAPH Best-in-Show Award two times.</br></br>

		Prior to NIVIDA, I was a Principal Research Scientist with Mitsubishi Electric Research Laboratories (MERL). I received my Ph.D. degree from the University of Maryland, College Park, MD, USA, in 2012, advised by <a href="chellappa">Prof. Rama Chellappa</a>.
		</br></br>

		<a href="https://github.com/mingyuliuthttps://scholar.google.com/citations?user=y-f-MZgAAAAJ&hl=enw" accesskey="6" title=""><img src="images/scholar.jpg" alt="" width="40" class="left" /></a>
		<a href="https://github.com/mingyuliutw" accesskey="6" title=""><img src="images/github.jpg" alt="" width="40" class="left" /></a>
		<a href="https://twitter.com/liu_mingyu" accesskey="6" title=""><img src="images/twitter.jpg" alt="" width="43" class="left" /></a>
		<a href="https://www.linkedin.com/in/mingyuliu/" accesskey="6" title=""><img src="images/linkedin.jpg" alt="" width="42" class="left"/></a>
	</td>
	</tr>
	</table>
	</h2>

			
	</div>
	<p class="meta"></p>
</div>

<hr />
<div id= "award">
<div id="latest-post" class="post"><h2><b>Awards</b></h2>
	<div class="entry">
	<h3>
	<ul>
		<li>
			<p><a href="https://twitter.com/siggraph/status/1425261704678682626?s=20">Best in Show Award , SIGGRAPH Real-Time-Live 2021</a>
		</li>				
		<li>
			<p><a href="https://www.forbes.com/sites/kenrickcai/2021/01/04/forbes-ai-awards-2020-meet-gpt-3-the-computer-program-that-can-write-an-op-ed/?sh=6866ea0b93a7">Most Disruptive Inventor Award, Forbes 2020</a>
		</li>
		<li>
			<p><a href="https://www.popsci.com/story/technology/best-of-whats-new-2019/#">Best of What's New Award, Popular Science Magazine 2019</a>
		</li>			
		<li>
			<p><a href="https://s2019.siggraph.org/conference/programs-events/real-time-live/">Best in Show Award and Audience Choice Award, SIGGRAPH Real-Time-Live 2019</a>
		</li>			
		<li>
			<p><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjChuizobjwAhUkJDQIHV8MDUEQFjAAegQIBBAD&url=https%3A%2F%2Fcvpr2019.thecvf.com%2Ffiles%2FCVPR%25202019%2520-%2520Welcome%2520Slides%2520Final.pdf&usg=AOvVaw20JOysDo6G5gvCa_k8Q4t9">Best Paper Finalist, CVPR 2019</a>
		</li>			
		<li>
		    <p> 1st place, Domain Adaptation for Semantic Segmentation Competition, WAD Challenge, CVPR 2018
		</li>		
		<li>
		    <p> 1st place, Optical Flow Competition, Robust Vision Challenge, CVPR 2018
		</li>	
		<li>
		    <p> Outstanding Reviewer, CVPR 2018
		</li>
		<li>
		    <p> Pioneer Research Award, NVIDIA 2017, 2018
		</li>
		<li>
		    <p> NTECH Best Presenter Award, NVIDIA 2017
		</li>
		<li>
		    <p> CR&D Award, Mitsubishi Electric Research Labs (MERL) 2016
		</li>			
		<li>
		    <p> Best paper finalist, Robotics Science and Systems (RSS) Conference 2015
		</li>				  
		<li>		  
		    <p><a href="https://www.mitsubishielectric.com/news/2014/0806.html">R&D 100 award, R&D Magazine 2014</a></h3>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	



<hr />
<div id="service">
<div id="latest-post" class="post"><h2><b>Research community service</b></h2>
	<div class="entry">
	<ul>
		<li> 
			<h3>Conference Program Chair: WACV (2020)</h3>
		</li>			
		<li> 
			<h3>Conference Area Chair: NeurIPS (2020, 2021), ICML (2021), ICLR (2021, 2022), CVPR (2020, 2022), ICCV (2019), ECCV (2020), BMVC (2019), WACV (2019)</h3>
		</li>		
		<li> 
			<h3>Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR</h3>
		</li>
		<li> 
			<h3>Journal Reviewer: TPAMI, IJCV, TIP, TMM, CVIU</h3>
		</li>
		<li> 
			<h3>Journal guess editor: IJCV (Special Issue on GANs)</h3>
		</li>	
		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="tutorial">
<div id="latest-post" class="post"><h2><b>Co-hosted Tutorials</b></h2>
	<div class="entry">
	<ul>
		<li>
		  <h3><a href="https://nvlabs.github.io/iccv2019-mixed-precision-tutorial/">[Site]</a> ICCV 2019 Tutorial on Accelerating Computer Vision with Mixed Precision</h3>
		</li>		
		<li>
		  <h3><a href="https://mingyuliutw.github.io/icip2019-image-translation-tutorial/index.html">[Site]</a> ICIP 2019 Tutorial: Image-to-Image Translation</h3>
		</li>
		<li>
		  <h3><a href="https://nvlabs.github.io/dl-for-content-creation/">[Site]</a> CVPR 2019 Tutorial: Deep Learning for Content Creation</h3>
		</li>
		<li>
		  <h3><a href="https://github.com/mingyuliutw/cvpr2017_gan_tutorial">[Site]</a> CVPR 2017 Tutorial: Theory and Applications of Generative Adversarial Networks</h3>
		</li>	
		<li>
		  <h3><a href="tutorial/accv2016_dl_tutorial/index.html">[Site]</a> ACCV 2016 Tutorial: Deep Learning for Vision Guided Language Generation and Image Generation</h3>
		</li>		
		</ul>
	</ul>	
	</div>
</div>	

<hr />
<div id="workshop">
<div id="latest-post" class="post"><h2><b>Co-hosted Workshops</b></h2>
	<div class="entry">
	<ul>
		<li>
		  <h3><a href="http://visual.cs.brown.edu/aicc2020/">[Site]</a> CVPR 2021 Workshop: Content Creation</h3>
		</li>		
		<li>
		  <h3><a href="http://visual.cs.brown.edu/aicc2020/">[Site]</a> CVPR 2020 Workshop: Content Creation</h3>
		</li>		
		<li>
		  <h3><a href="https://sites.google.com/berkeley.edu/iccv-2019-image-and-video-syn">[Site]</a> ICCV 2019 Workshop: Image and Video Synthesis: How, Why and "What if"?</h3>
		</li>	
		<li>
		  <h3><a href="http://www.vision.ee.ethz.ch/aim19/">[Site]</a> ICCV 2019 Workshop: Advances in Image Manipulation workshop and challenges on image and video manipulation</h3>
		</li>		
		<li>
		  <h3><a href="http://www.vision.ee.ethz.ch/ntire19/">[Site]</a> CVPR 2019 Workshop: 4th New Trends in Image Restoration and Enhancement workshop and challenges</h3>
		</li>
		<li>
		  <h3><a href="https://www.aicitychallenge.org/">[Site]</a>CVPR 2019 Workshop: AI City Challenge</h3>
		</li>			
		<li>
		  <h3><a href="https://www.aicitychallenge.org/">[Site]</a> CVPR 2018 Workshop: AI City Challenge</h3>
		</li>
		</ul>
	</ul>	
	</div>
</div>	


<div id="footer">
	<p class="legal">&copy;2021 All Rights Reserved.</p>
</div>
</body>
</html>

